# Lab 200

This workshop comes with an OpenTelemetry Collector instance defined in the
docker-compose YAML file. In addition, an [initial configuration
file](configs/config.yaml) exists. In this lab, you will experience sending
different synthetic data to the collector and modifying the collector's
configuration to change behavior.

For all parts of Lab 200, the Collector will be started with:

```bash
cd docker
docker-compose run -p13133:13133 -p55679:55679 -p8081:8081 \
                   -p8888:8888   -p9091:9090   -p9411:9411 otelcol
```

Once running, you can:

- See the collector's own metrics at `http://localhost:8888/metrics`
- View zPages data at `http://localhost:55679/debug/servicez` or
`http://localhost:55679/debug/tracez`
- View health check information at `http://localhost:13133`

## Lab 201: Processing trace data with the OpenTelemetry Collector

In Lab 102, you configuration an application to send data to a collector. Now,
we will use a synthetic, single-span trace provided [here](data/trace.json).

A) Let's test sending synthetic data to the collector:

- Start just the collector as defined above
- In a separate terminal window POST the synthetic data
```bash
cd docker
curl -X POST -d @data/trace.json http://localhost:9411/api/v1/trace
```
- What do you see in the collector logs?
```bash
2021-09-29T01:07:30.768Z	INFO	loggingexporter/logging_exporter.go:41	TracesExporter	{"#spans": 1}
```
- Stop the collector (CTRL + C)

B) Uncomment the `loglevel` option in the [collector config](config/config.yml).
Perform the above steps again. What does the collector logs emit now?

C) What if we want to add a piece of metadata to all spans that pass through the
collector? For example, let's say we want to add a `deployment.environment` tag
to all spans. Uncomment the relevant options in the collector configuration and
repeat the exercise again. What happened this time?

D) Did you notice this trace contains sensitive information? For example, the
`ssn` tag and even possibly the `user` tag is sensitive. In addition, the query
param after the URL path potentially contains some useful metadata. We can use
the [attributes
processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/attributesprocessor)
to modify this data. Your task is to modify collector configuration using the attributes processor and:

- Delete the `ssn` tag
- Hash the `user` tag
- Extrace the key/value pair query param

## Lab 202: Collecting and processing metric data with the OpenTelemetry Collector

Now let's play with metrics. For this lab, we will leverage the synthetic
[metric data](data/metric.json).

A) In order to collect this data a metrics pipeline needs to be defined in the
collector configuration. Ensure the following criteria are met:

- Uses the `collectd` receiver
- Uses the `batch` processor
- Uses the `logging` and `prometheus` exporters

B) Let's test sending synthetic data to the collector:

- Start just the collector as defined above
- In a separate terminal window POST the synthetic data
```bash
cd docker
curl -X POST -d @data/metric.json http://localhost:8081
```
- What do you see in the collector logs?
```bash
2021-09-29T01:07:30.768Z	INFO	loggingexporter/logging_exporter.go:41	MetricsExporter	{"#metrics": 1}
```
- Stop the collector (CTRL + C)

C) What if we want to add a piece of metadata to all spans that pass through the
collector? For example, let's say we want to add a `deployment.environment` tag
to all spans. Edit the collector configuration to support this and test to
ensure it is working.

D) Let's test synthetic metric data > otelcol > prometheus. To do this, run
`docker-compose up` and then POST the synthetic data `curl -X POST -d
@data/metric.json http://localhost:8081`. Now, open
[prometheus](http://localhost:9090) and search for `cpu_idle`.

BONUS: Use the [metrics transform
processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor)
to add a new `foo` label. Set the value as `bar`.

## Lab 203: Collecting and processing log data with the OpenTelemetry Collector

A JSON log file is mounted in docker-compose of otelcol in `/data/log.json`.
Capture this log using the `filelog` receiver. Some things to consider:

- What does the pipeline need to look like?
- How can you capture an already existing file?
- How would you go about parsing the timestamp?
- How (what processor) would you change metadata?
